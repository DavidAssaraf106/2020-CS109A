{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "## Homework 5: High Dimensionality and PCA\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2020**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader, and Chris Tanner\n",
    "\n",
    "<hr style=\"height:2.4pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "\tbackground-color: #fce8e8;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".jp-MarkdownCell {background-color: cornsilk;}\n",
       ".text_cell {background-color: cornsilk;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".jp-MarkdownCell {background-color: cornsilk;}\n",
    ".text_cell {background-color: cornsilk;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS CELL\n",
    "import os\n",
    "import pathlib\n",
    "working_dir = pathlib.Path().absolute()\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ac03bc-f0ec-4c6b-a41a-9c8eeaa80770",
    "colab_type": "text",
    "id": "-5WJkGo16514"
   },
   "source": [
    "<hr style=\"height:2pt\">\n",
    "\n",
    "### INSTRUCTIONS\n",
    "\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "\n",
    "- This homework can be submitted in pairs, and it is encouraged for you to do so. Especially during covid and distancing, this can be a way to work with other students and learn alongside one another. As future data scientists, you will often be expected to work with others, and working in pairs can help practice communicating data science concepts.\n",
    "\n",
    "- Please restart the kernel and run the entire notebook again before you submit.\n",
    "\n",
    "- Running cells out of order is a common pitfall in Jupyter Notebooks. To make sure your code works restart the kernel and run the whole notebook again before you submit. Exceptions should be made for code with a long execution time, of course.\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports statement at the top of this notebook. We strongly suggest that you use those and not others as we may not be familiar with them. .\n",
    "- Please use .head() when viewing data. Do not submit a notebook that is **excessively long**. \n",
    "- In questions that require code to answer, such as \"calculate the $R^2$\", do not just output the value from a cell. Write a `print()` function that includes a reference to the calculated value, **not hardcoded**. For example: \n",
    "```\n",
    "print(f'The R^2 is {R:.4f}')\n",
    "```\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='theme'> Cancer Classification from Gene Expressions </div>\n",
    "\n",
    "In this assignment, we will build several classification models to distinguish between two related classes of cancer, acute lymphoblastic leukemia (ALL) and acute myeloid leukemia (AML), using gene expression measurements. The .csv data file is provided in the compressed file `data/hw5_genes_multiclass.zip`. Each row in this file corresponds to a tumor tissue sample from a patient with one of the two forms of leukemia.  Note: there are two different forms of the response variable. \n",
    "\n",
    "- The first column contains `Cancer_type`: **0 = ALL** class and **1 = AML** class\n",
    "- Columns 2-7130 contain expression levels of 7129 genes recorded from each tissue sample \n",
    "- The last column `Cancer_subtype` additionally distinguishes between two subtypes of ALL, subtype T and subtype B (used in problem 5): **0 = ALL subtype T**, **1 = ALL subtype B**, **2 = type AML**. \n",
    "\n",
    "In the following questions, we will use logistic regression and PCA to build classification models for this data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Question 1 [20 pts]: Data Exploration](#Question-1-[20-pts]:-Data-Exploration) \n",
    "- [Question 2 [25 pts]: Logistic Regression Modeling](#Question-2-[25-pts]:-Logistic-Regression-Modeling) \n",
    "- [Question 3 [20 pts]: Performing Principal Components Analysis](#Question-3-[20-pts]:-Performing-Principal-Components-Analysis)\n",
    "- [Question 4 [10 pts]: Principal Components Regression (PCR)](#Question-4-[10-pts]:-Principal-Components-Regression-(PCR))\n",
    "- [Question 5 [25 pts]: Multi-Class Response](#Question-5-[25-pts]:-Multi-Class-Response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class='exercise'><b>Question 1 [20 pts]: Data Exploration</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[▲ Return to contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to split the observations into an approximate 75-25 train-test split.  Below we provide some code to do this for you (we want to make sure everyone has the same splits). It also prints the dataset shape before splitting and after splitting. `Cancer_type` is our response variable for problems 1-4, while `Cancer_subtype` is the response variable in problem 5.\n",
    "\n",
    "\n",
    "**1.1** Take a peek at your training set: you should notice the severe differences in the measurements from one gene to the next (some are negative, some hover around zero, and some are well into the thousands). To account for these differences in scale, normalize each predictor to vary between 0 and 1.   **NOTE: for the entirety of this homework assignment, you will use these normalized values, not the original, raw values**.\n",
    "\n",
    "\n",
    "**1.2** The training set contains more predictors than observations. What problem(s) can this lead to in fitting a classification model to such a dataset? Explain in 3 or fewer sentences.\n",
    "\n",
    "\n",
    "**1.3** Determine which 10 genes best individually discriminates between the two cancer classes (Note: consider every gene in the dataset).  Then determine the single best gene predictor.  Plot two sets of histograms of your `best_predictor` -- one using the training set and another using the test set.  The histograms should clearly distinguish two different `Cancer_type` classes.\n",
    "\n",
    "**Hint:** You may use any reasonable approach to determine the `best_predictor`, but please use something very simple (whether taught in this class or elsewhere).\n",
    "\n",
    "**1.4** Using `best_predictor`, create a classification model by eye-balling a value for this gene that would best discriminate the two cancer classes in the training set. (Note: Do not use an algorithm to determine for you the optimal coefficient or threshold; we are asking you to provide a rough estimate / model by manual inspection.) Justify your choice of value in 1-2 sentences. Report the accuracy of your hand-chosen model on the train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(752, 7131)\n",
      "(564, 7129) (188, 7129) (564,) (188,)\n",
      "0.0    0.511968\n",
      "1.0    0.488032\n",
      "Name: Cancer_type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "## DO NOT MODIFY THIS CODE ##\n",
    "#############################\n",
    "\n",
    "np.random.seed(109)\n",
    "#zf = zipfile.ZipFile('data/hw5_genes_multiclass.csv.zip') \n",
    "df = pd.read_csv('data/hw5_genes_multiclass.csv')\n",
    "X = df.drop(['Cancer_type','Cancer_subtype'], axis=1)\n",
    "X_train, X_test, y_train, y_test, y2_train, y2_test  = train_test_split(\n",
    "    X, df.Cancer_type, df.Cancer_subtype, test_size=0.25, random_state = 109,\n",
    "    stratify = df.Cancer_subtype)\n",
    "\n",
    "print(df.shape)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(df.Cancer_type.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.1",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**1.1** Take a peek at your training set: you should notice the severe differences in the measurements from one gene to the next (some are negative, some hover around zero, and some are well into the thousands). To account for these differences in scale, normalize each predictor to vary between 0 and 1.   **NOTE: for the entirety of this homework assignment, you will use these normalized values, not the original, raw values**.\n",
    " \n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.2",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**1.2** The training set contains more predictors than observations. What problem(s) can this lead to in fitting a classification model to such a dataset? Explain in 3 or fewer sentences.\n",
    " \n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.3",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**1.3** Determine which 10 genes best individually discriminates between the two cancer classes (Note: consider every gene in the dataset).  Then determine the single best gene predictor.  Plot two sets of histograms of your `best_predictor` -- one using the training set and another using the test set.  The histograms should clearly distinguish two different `Cancer_type` classes.\n",
    " \n",
    " **Hint:** You may use any reasonable approach to determine the `best_predictor`, but please use something very simple (whether taught in this class or elsewhere).\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.4",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    "    \n",
    "**1.4** Using `best_predictor`, create a classification model by eye-balling a value for this gene that would best discriminate the two cancer classes in the training set. (Note: Do not use an algorithm to determine for you the optimal coefficient or threshold; we are asking you to provide a rough estimate / model by manual inspection.) Justify your choice of value in 1-2 sentences. Report the accuracy of your hand-chosen model on the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class='exercise'><b>Question 2 [25 pts]: Logistic Regression Modeling</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[▲ Return to contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** Fit a simple logistic regression model to the training set using the single gene predictor `best_predictor` to predict cancer type. Calculate and display the training and test classification accuracies of this model. \n",
    "How do accuracies compare to the eye-balled ones from 1.4? \n",
    "\n",
    "**2.2** Next, fit a multiple logistic regression model with **all** the gene predictors from the data set (reminder: for this assignment, we are always using the normalized values).  \n",
    "How does the classification accuracy of this model compare with the logistic and eyeballed models above which were fit with a single gene? Be sure to evaluate both the training and test sets.\n",
    "\n",
    "**2.3** Print out the logistic regression coefficients for  `best_predictor` from the simple logistic and multiple logistic regression models in part 1 and part 2 above.  Interpret the coefficients: Do they agree or disagree?  What does this indicate?\n",
    "\n",
    "**2.4** Now let's use regularization to improve the predictions from the multiple logistic regression model. Specifically, use LASSO-like regularization and 5-fold cross-validation to fit the model on the training set. \n",
    "Report the chosen best value of the regularization hyperparamter and the classification accuracy on both the training and test sets.\n",
    "\n",
    "**2.5** Compare the classification accuracies (both train and test) between the un-regularized multiple logistic regression model to the regularized one. Briefly explain why these results occur.\n",
    "\n",
    "**2.6** How many predictors are considered as important features in this regularized model?  What does that say about the full logistic regression model in problem 2.2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.1",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**2.1** Fit a simple logistic regression model to the training set using the single gene predictor `best_predictor` to predict cancer type. Calculate and display the training and test classification accuracies of this model.\n",
    " How do accuracies compare to the eye-balled ones from 1.4?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.2",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**2.2** Next, fit a multiple logistic regression model with **all** the gene predictors from the data set (reminder: for this assignment, we are always using the normalized values).\n",
    " How does the classification accuracy of this model compare with the logistic and eyeballed models above which were fit with a single gene? Be sure to evaluate both the training and test sets.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.3",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**2.3** Print out the logistic regression coefficients for  `best_predictor` from the simple logistic and multiple logistic regression models in part 1 and part 2 above.  Interpret the coefficients: Do they agree or disagree?  What does this indicate?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.4",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**2.4** Now let's use regularization to improve the predictions from the multiple logistic regression model. Specifically, use LASSO-like regularization and 5-fold cross-validation to fit the model on the training set.\n",
    " Report the chosen best value of the regularization hyperparamter and the classification accuracy on both the training and test sets.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.5",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**2.5** Compare the classification accuracies (both train and test) between the un-regularized multiple logistic regression model to the regularized one. Briefly explain why these results occur.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.6",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    "    \n",
    "**2.6** How many predictors are considered as important features in this regularized model?  What does that say about the full logistic regression model in problem 2.2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class='exercise'><b>Question 3 [20 pts]: Performing Principal Components Analysis</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[▲ Return to contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Create the full PCA decomposition of `X_train` and apply the transformation to both `X_train` and `X_test`.  Report the shape of both of these.  What is the limiting factor for the maximum number of PCA components for this data set? \n",
    "\n",
    "**3.2** PCA is often solely used to help in visualizing high-dimensional problems.  Plot the scatterplot of the second PCA vector of train on the $Y$-axis and the first PCA vector of train on the $X$-axis (be sure to denote the classes via different colors and markings).  In 2-3 sentences, explain why using the scatterplot of the top two PCA vectors is a useful approach to visualize a high dimensional classification problem.\n",
    "\n",
    "**3.3** Determine and report the variance explained in `X_train` based on the top two PCA vectors.  Determine and report how many PCA vectors are needed so that 90\\% of the variability in the predictors is explained, and create a plot to illustrate this result (Hint: look at cumulative explained variability vs. number of PCA components used).\n",
    "\n",
    "**3.4** Plot explained variability in the predictors on the $Y$-axis and the PCA component number on the $X$-axis. Select a reasonable value for the number of components that balances representativeness (of the predictors) with parsimony."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.1",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**3.1** Create the full PCA decomposition of `X_train` and apply the transformation to both `X_train` and `X_test`.  Report the shape of both of these.  What is the limiting factor for the maximum number of PCA components for this data set?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.2",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**3.2** PCA is often solely used to help in visualizing high-dimensional problems.  Plot the scatterplot of the second PCA vector of train on the $Y$-axis and the first PCA vector of train on the $X$-axis (be sure to denote the classes via different colors and markings).  In 2-3 sentences, explain why using the scatterplot of the top two PCA vectors is a useful approach to visualize a high dimensional classification problem.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.3",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**3.3** Determine and report the variance explained in `X_train` based on the top two PCA vectors.  Determine and report how many PCA vectors are needed so that 90\\% of the variability in the predictors is explained, and create a plot to illustrate this result (Hint: look at cumulative explained variability vs. number of PCA components used).\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.4",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    "    \n",
    "**3.4** Plot explained variability in the predictors on the $Y$-axis and the PCA component number on the $X$-axis. Select a reasonable value for the number of components that balances representativeness (of the predictors) with parsimony."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class='exercise'><b>Question 4 [10 pts]: Principal Components Regression (PCR)</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[▲ Return to contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1** Fit three separate Logistic Regression models using principal components as the predictors: (1) with just the first two PCA vectors, (2) with the number of component vectors you chose from problem 3 above, and (3) with the number of components that explain at least 90% of the variability in the predictor set. How do the classification accuracy values on both the training and test sets compare with the models fit in Question 2?\n",
    "\n",
    "**4.2** Use cross-validation to determine the best number of principal components. Try out the 3 values from the previous sub-part and optionally include other values as well. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.1",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**4.1** Fit three separate Logistic Regression models using principal components as the predictors: (1) with just the first two PCA vectors, (2) with the number of component vectors you chose from problem 3 above, and (3) with the number of components that explain at least 90% of the variability in the predictor set. How do the classification accuracy values on both the training and test sets compare with the models fit in Question 2?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.2",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    "    \n",
    "**4.2** Use cross-validation to determine the best number of principal components. Try out the 3 values from the previous sub-part and optionally include other values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class='exercise'><b>Question 5 [25 pts]: Multi-Class Response</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[▲ Return to contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, there are actually two subtypes of `ALL` cancer: B-cell and T-cell.  The variable `Cancer_subtype` designates the 3 cancer cubtypes: \n",
    "- 0 = ALL Type T, \n",
    "- 1 = ALL Type B, and \n",
    "- 2 = AML.  \n",
    "Use this updated response variable to answer the following questions:\n",
    "\n",
    "**5.1** Fit two separate well-tuned, regularized (Ridge-like), multinomial logistic regression models to predict `Cancer_subtype`. For the first model, use the first two PCA components as predictors. For the second model, include  the quadratic and interaction terms for the first two PCA components, for a total of five predictors. Print and evaluate (with two or three sentences) the classification accuracy of the two models, on both train and test.\n",
    "\n",
    "**5.2** Create two separate scatter plots (one will be for each model above) of the first two principal components of the test data and denote the three cancer types by different color and marker.  Plot the decision boundaries separately on the two scatterplots and interpret the results:  which model appears to draw more reasonable decision boundaries?  Do the first two principal components appear to provide enough predictive power for this classification problem?\n",
    "\n",
    "**Hint: you can use the `meshgrid` as seen in lecture exercises to generate the decision boundaries.**\n",
    "\n",
    "**5.3** Use cross-validation to determine the best number of principal components for this multiclass problem. Consider the set of [2, 5, 10, 15, 20, 50, and 100] components.  Be sure to clearly substantiate your choice.\n",
    "\n",
    "**5.4** For your best model in the previous part, determine the classification accuracies within each observed (not predicted) subtype in test: which group is the most difficult to classify accurately?  Is this surprising?  Why or why not?\n",
    "\n",
    "**5.5** In the 2-class problem the classification threshold can be altered from 0.5 to affect the number of false positives and false negatives (this is what the ROC curve is based on). In the multiclass setting, the predicted class probabilities can be weighted to determine the winning class (so that a smaller class will not be 'ignored' by the algorithm): essentially, each class's predicted probability can be multiplied by this class weight and compared to determine the classification.\n",
    " \n",
    "Determine the classification accuracies in each observed subtype in test if instead the observations were weighted more 'fairly': they are inversely weighted based on the observed sample sizes in train (so that if there were just 2 groups in the response with 75% of the response in one class and 25% in the other, the smaller class should be weighted 3 times as much as the larger class).  \n",
    "\n",
    "Report the weights you used and the resulting classification accuracies in each subtype.  In what way have the results improved?  In what way have the results not improved?  Comment with 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.1",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.1** Fit two separate well-tuned, regularized (Ridge-like), multinomial logistic regression models to predict `Cancer_subtype`. For the first model, use the first two PCA components as predictors. For the second model, include  the quadratic and interaction terms for the first two PCA components, for a total of five predictors. Print and evaluate (with two or three sentences) the classification accuracy of the two models, on both train and test.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.2",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.2** Create two separate scatter plots (one will be for each model above) of the first two principal components of the test data and denote the three cancer types by different color and marker.  Plot the decision boundaries separately on the two scatterplots and interpret the results:  which model appears to draw more reasonable decision boundaries?  Do the first two principal components appear to provide enough predictive power for this classification problem?\n",
    " \n",
    " **Hint: you can use the `meshgrid` as seen in lecture exercises to generate the decision boundaries.**\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.3",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.3** Use cross-validation to determine the best number of principal components for this multiclass problem. Consider the set of [2, 5, 10, 15, 20, 50, and 100] components.  Be sure to clearly substantiate your choice.\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.4",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.4** For your best model in the previous part, determine the classification accuracies within each observed (not predicted) subtype in test: which group is the most difficult to classify accurately?  Is this surprising?  Why or why not?\n",
    " \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "5.5",
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>  \n",
    " \n",
    "**5.5** In the 2-class problem the classification threshold can be altered from 0.5 to affect the number of false positives and false negatives (this is what the ROC curve is based on). In the multiclass setting, the predicted class probabilities can be weighted to determine the winning class (so that a smaller class will not be 'ignored' by the algorithm): essentially, each class's predicted probability can be multiplied by this class weight and compared to determine the classification.\n",
    " \n",
    " Determine the classification accuracies in each observed subtype in test if instead the observations were weighted more 'fairly': they are inversely weighted based on the observed sample sizes in train (so that if there were just 2 groups in the response with 75% of the response in one class and 25% in the other, the smaller class should be weighted 3 times as much as the larger class).\n",
    " \n",
    " Report the weights you used and the resulting classification accuracies in each subtype.  In what way have the results improved?  In what way have the results not improved?  Comment with 2-3 sentences.\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw1-part1.ipynb",
   "provenance": []
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "5e5027d5-1cf7-4394-a1d5-c57eaedde1db",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
